# ðŸ“‚ `train_and_evaluate`Â â€”Â Training & Evaluation Guide

This folder hosts **selfâ€‘contained scripts** for fineâ€‘tuning small language models on the Mentalâ€‘Emotion dataset with 4â€‘bit **QLoRA** and evaluating their performance.

> **Scope** Â· Oneâ€‘shot experiments for research validation, *not* a production pipeline.

---

## 1. Folder Layout

```text
train_and_evaluate/
â”œâ”€â”€ QLoRA_Qwen_2.5_3B_train.py   # Fineâ€‘tunes Qwenâ€‘2.5â€‘3B
â”œâ”€â”€ QLoRA_Llama_3.2_3B_train.py  # Fineâ€‘tunes Llamaâ€‘3.2â€‘3B
â””â”€â”€ outputs/                     # <scriptâ€‘generated> checkpoints & logs
```

Each script internally downloads (or reâ€‘uses) the base checkpoint to `<ROOT_PATH>/pretrained_models/<MODEL_NAME>`.

---

## 2. Prerequisites

| Requirement | Minimum                                                                                        | Notes                          |
| ----------- | ---------------------------------------------------------------------------------------------- | ------------------------------ |
| **Python**  | 3.10+                                                                                          | Tested on 3.11                 |
| **CUDA**    | 12.1                                                                                           | NVIDIA Ampereâ†‘ GPU (bfloat16)  |
| **VRAM**    | â‰¥â€¯24â€¯GB                                                                                        | Effective batch = 16 (1Ã—16 GA) |
| **PyPI**    | `transformers>=4.40.0`, `datasets`, `bitsandbytes`, `peft`, `accelerate`, `wandb` *(optional)* |                                |

Install once:

```bash
pip install -r requirements.txt  # or copy the list above
```

> **Tip** Â If compilation of **bitsandbytes** fails, use the official preâ€‘built wheels:
> `pip install bitsandbytes-cuda121` (or your CUDA version).

---

## 3. Data Preparation

1. Run the prompting script **once** to create training/test CSVs:

   ```bash
   python ../Tiny-Mental-LLM/Mental_Emotion_Dataset/raw_dataset/DepSeverity/add_prompt.py \
          --seed 42 --train_ratio 0.9
   ```

2. Place or symlink the resulting folder
   `Tiny-Mental-LLM/Mental_Emotion_Dataset/prompted_dataset/DepSeverity/`
   next to this `train_and_evaluate` directory **or** pass its path via `--train_file` / `--eval_file`.

Dataset CSVs must contain exactly two columns:

```csv
text,label
"I feel empty inside...",2
...
```

---

## 4. Quickâ€‘Start Commands

### Qwenâ€‘2.5â€‘3B (4â€‘bit QLoRA)

```bash
python QLoRA_Qwen_2.5_3B_train.py \
  --root_path /workspace/iclab_slm \
  --train_file ../Tiny-Mental-LLM/.../train.csv \
  --eval_file  ../Tiny-Mental-LLM/.../test.csv \
  --batch_size 1 --gradient_accumulation_steps 16 \
  --num_epochs 3 --seed 42
```

### Llamaâ€‘3.2â€‘3B (4â€‘bit QLoRA)

```bash
python QLoRA_Llama_3.2_3B_train.py \
  --root_path /workspace/iclab_slm \
  --train_file ... --eval_file ...
```

Both scripts share a common argument schema:

| Flag                            | Default           | Meaning                                                |
| ------------------------------- | ----------------- | ------------------------------------------------------ |
| `--root_path`                   | **REQUIRED**      | Project root where `pretrained_models/` lives          |
| `--train_file` / `--eval_file`  | Relative CSV path | Custom dataset location                                |
| `--batch_size`                  | 1                 | GPU microâ€‘batch size                                   |
| `--gradient_accumulation_steps` | 16                | Accumulate steps to reach effective batch *(batchÃ—GA)* |
| `--max_length`                  | 512               | Context length (tokens)                                |
| `--num_epochs`                  | 3                 | Fineâ€‘tuning epochs                                     |
| `--seed`                        | 42                | RNG seed for reproducibility                           |

> **bfloat16 note** â€‘ Scripts set `bf16=True`; disable with `--no_bf16` when using older GPUs.

---

## 5. Outputs

After each epoch the *best* checkpoint (lowest loss) is saved to

```
train_and_evaluate/outputs/<model>-qlora-<timestamp>/
â”œâ”€â”€ adapter_config.json   # LoRA adapter
â”œâ”€â”€ adapter_model.bin     # Trained Î”â€‘weights (few MB)
â”œâ”€â”€ trainer_state.json    # Log history
â””â”€â”€ ...
```

Keep the base model in `pretrained_models/` and load the adapter via PEFT:

```python
from peft import PeftModel
from transformers import AutoModelForCausalLM

base = AutoModelForCausalLM.from_pretrained("qwen/Qwen1.5-4B")
model = PeftModel.from_pretrained(base, "outputs/qwen-qlora-2025-05-11")
```

---

## 6. Evaluation & Perplexity

Each script runs an **epochâ€‘level eval** pass (`Trainer.evaluate`) and prints
perplexity (if `compute_metrics` is enabled) to stdout and `trainer_state.json`.
For custom metrics add a `compute_metrics()` function near the bottom of the script.

Example:

```python
def compute_metrics(eval_preds):
    logits, labels = eval_preds
    preds = logits.argmax(-1)
    acc = (preds == labels).mean()
    return {"accuracy": acc}
```

---

## 7. Reproducibility Checklist

* `--seed` passed â†’ seeds Python, NumPy, PyTorch, and `random`.
* `deterministic=True` is set internally when the seed flag is on.
* Split files are versionâ€‘controlled; reâ€‘generate only with explicit seed.

---

## 8. Troubleshooting

| Symptom                                   | Likely Cause                    | Fix                                                           |
| ----------------------------------------- | ------------------------------- | ------------------------------------------------------------- |
| **CUDA out of memory**                    | batch Ã— GA too high             | Lower `--gradient_accumulation_steps` or `--max_length`       |
| `RuntimeError: bf16 not supported`        | GPU < Ampere                    | Add `--no_bf16` flag (casts to fp16)                          |
| `AttributeError: tril` during ONNX export | PyTorch / transformers mismatch | Upgrade PyTorch â‰¥Â 2.2 or apply monkeyâ€‘patch (see `sLM_SNPE/`) |

If issues persist, raise an [Issue](https://github.com/yourâ€‘org/yourâ€‘repo/issues) with full logs.

---

## 10. Practical QLoRA & LoRA Tips

Below is a distilled checklist of actionable advice drawn from Sebastianâ€¯Raschkaâ€™s *â€œPractical Tips for Fineâ€‘Tuningâ€¯LMs Usingâ€¯LoRAâ€* article on Continuumâ€¯LabsÂ¹. These apply equally to our QLoRA scripts in this folder.

| Area                       | Tip                                                                                                                           |
| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **Layer Coverage**         | Apply LoRA to **all linear layers** (Q,â€¯K,â€¯V, O *and* MLP projections) for best accuracyâ€”KVâ€‘only adapters often underperform. |
| **RankÂ (r) & AlphaÂ (Î±)**   | Start with **Î±Â â‰ˆâ€¯2â€¯Ã—â€¯r**. Scaling factor Î±/r should neither explode (>32) nor vanish (<1).                                    |
| **QLoRA Tradeâ€‘offs**       | 4â€‘bit QLoRA cuts **\~â…“ VRAM** but slows training by **â‰ˆâ€¯40â€¯%**; use when memoryâ€‘bound.                                        |
| **Optimizer Choice**       | AdamW, AdamWÂ + scheduler, or SGDÂ + scheduler perform similarly; plain SGD lags.                                               |
| **Epoch Count**            | More epochs â‰  betterâ€”multiâ€‘epoch passes on the *same* small dataset quickly overfit. Monitor val loss & stop early.           |
| **Reproducibility**        | Despite GPU nondeterminism, LoRA runs are **remarkably consistent**. Fix seeds and log configs to compare fairly.             |
| **Singleâ€‘GPU Feasibility** | With QLoRA (r=256,â€¯Î±=512) you can fineâ€‘tune a **7â€¯B** model in â‰ˆâ€¯3â€¯h on one A100 (14â€¯GB).                                     |
| **Memory Hotspots**        | Most memory goes to activations, not Adam states; Adamâ€™s 2Ã— param overhead is negligible for LLMs.                            |
| **Combining Adapters**     | You can merge or stack multiple LoRA adapters for multiâ€‘domain expertiseâ€”experiment!                                          |

Â¹Â [https://training.continuumlabs.ai/training/the-fine-tuning-process/parameter-efficient-fine-tuning/practical-tips-for-fine-tuning-lms-using-lora-low-rank-adaptation](https://training.continuumlabs.ai/training/the-fine-tuning-process/parameter-efficient-fine-tuning/practical-tips-for-fine-tuning-lms-using-lora-low-rank-adaptation)

---

## 9. Citation & Credits

* **Qwenâ€‘2.5â€‘3B** â€” *Qwen Team, 2024*
* **Llamaâ€‘3.2â€‘3B** â€” *Meta AI, 2025*
* **QLoRA** â€” *Dettmers etÂ al., ICMLÂ 2023*

---

Happy fineâ€‘tuning! ðŸš€
